{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "import pytz\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data Ingestion\n",
    "\n",
    "### Arctic\n",
    "[Arctic](http://github.com/manahl/arctic) is a \"High performance datastore for time series and tick data\", built by the rather large hedge fund Man AHL and built on MongoDB. Generally speaking, I have avoided MongoDB in the past because, well, [it doesn't do what it says on the tin](https://aphyr.com/posts/322-jepsen-mongodb-stale-reads). This seems to have been [fixed](https://jepsen.io/analyses/mongodb-3-4-0-rc3), and in fairness, it's not too important if you lose a handful out of a few billion rows of timeseries data.\n",
    "\n",
    "Great video RE design: https://vimeo.com/album/3660528/video/145842301\n",
    "It's attractive how focused Arctic seems to be on working with Pandas\n",
    "\n",
    "\n",
    "Arctic expects to be able to read port '27017', so spin up that container with:\n",
    "`sudo docker-compose up -d mongo`\n",
    "\n",
    "\n",
    "CHUNKSTORE OR TICKSTORE?\n",
    "According to [this issue](https://github.com/manahl/arctic/issues/197), the TickStore is best for continuously reading/writing data (ticks), and the ChunkStore is best for writing large blocks at once. Arctic's authors use Kafka to queue and batch-write ~3 hours worth of ticks, I believe as a ChunkStore. Because the API is so easy to work with, we might as well test both approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data has 193.483396 million rows and takes up 4428.48348999 megabytes.\n"
     ]
    }
   ],
   "source": [
    "from arctic import TICK_STORE, CHUNK_STORE\n",
    "from arctic import Arctic\n",
    "\n",
    "# Initialize Arctic\n",
    "arctic_db = Arctic('localhost')\n",
    "arctic_db.initialize_library(\"fx_tickstore\", lib_type=TICK_STORE)\n",
    "arctic_db.initialize_library(\"fx_chunkstore\", lib_type=CHUNK_STORE)\n",
    "arctic_tick_lib = arctic_db[\"fx_tickstore\"]\n",
    "arctic_chunk_lib = arctic_db[\"fx_chunkstore\"]\n",
    "\n",
    "# Load the raw data\n",
    "all_files = glob.glob(\"./raw_data/*.csv\")\n",
    "raw = pd.concat((pd.read_csv(f, header=None, names=[\"symbol\",\"date\",\"bid\",\"ask\"]).drop(\"symbol\", 1) for f in all_files))\n",
    "\n",
    "raw[\"date\"] = pd.to_datetime(raw[\"date\"])\n",
    "raw = raw.set_index(\"date\").tz_localize(pytz.utc)\n",
    "\n",
    "# Save some information about how much data we have.\n",
    "num_rows = len(raw)\n",
    "num_bytes = raw.memory_usage().sum()\n",
    "\n",
    "print(\"Raw data has %s million rows and takes up %s megabytes.\" % (num_rows/1000000, num_bytes/1024/1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write the dataframe to Arctic\n",
    "def insert_to_arctic_tick():\n",
    "    arctic_tick_lib.delete(\"AUDUSD\")\n",
    "    arctic_tick_lib.write(\"AUDUSD\", raw)\n",
    "\n",
    "def insert_to_arctic_chunk():\n",
    "    arctic_chunk_lib.delete(\"AUDUSD\")\n",
    "    arctic_chunk_lib.write(\"AUDUSD\", raw)\n",
    "    \n",
    "timeit.timeit('insert_to_arctic_chunk()', 'from __main__ import insert_to_arctic_chunk', number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4643601504"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.memory_usage().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
